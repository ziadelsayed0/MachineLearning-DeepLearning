{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5463215,"sourceType":"datasetVersion","datasetId":3156070},{"sourceId":9748747,"sourceType":"datasetVersion","datasetId":5968335},{"sourceId":9775479,"sourceType":"datasetVersion","datasetId":5988228}],"dockerImageVersionId":30458,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ziadhamed/data-preprocessing-and-model-selection-regression?scriptVersionId=204569067\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Preprocessing Summary\n\nThis notebook covers essential preprocessing steps for preparing data for machine learning regression models. Each section performs a specific transformation on the data to ensure it's suitable for modeling. Below is a summary of the sections:\n\n1. **Dataset Importation**: The dataset is loaded using `pandas` for data manipulation and analysis.\n2. **Feature Selection**: Independent (X) and dependent (Y) variables are extracted from the dataset, where X contains the features, and Y is the target variable.\n3. **Handling Missing Values**: Missing values in the dataset are handled using `SimpleImputer`, which replaces `NaN` values with the mean of the respective feature.\n4. **Encoding Categorical Data**: The dataset contains categorical variables, which are encoded using `LabelEncoder` and `OneHotEncoder` to convert them into a numerical format suitable for machine learning algorithms.\n5. **Train-Test Split**: The data is split into training and testing sets using `train_test_split` from scikit-learn.\n6. **Feature Scaling**: Standardization of features is done with `StandardScaler`, which normalizes the feature values to ensure that each has a mean of 0 and a standard deviation of 1.\n\nThe diagram below illustrates these preprocessing steps:\n\n![Data Preprocessing Workflow](https://www.techtarget.com/rms/onlineimages/steps_for_data_preprocessing-f_mobile.png)\n","metadata":{}},{"cell_type":"code","source":"! pip install -U scikit-learn","metadata":{"id":"NeTri3Ay1Z1s","outputId":"7aff8ce1-119d-4fbe-d1da-fb0276a0c0ac","execution":{"iopub.status.busy":"2024-10-31T22:36:17.029871Z","iopub.execute_input":"2024-10-31T22:36:17.030181Z","iopub.status.idle":"2024-10-31T22:36:30.609897Z","shell.execute_reply.started":"2024-10-31T22:36:17.030127Z","shell.execute_reply":"2024-10-31T22:36:30.608809Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (1.0.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.21.6)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.7.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndataset = pd.read_csv('/kaggle/input/dataforpreprocessing/Data.csv')","metadata":{"id":"xvqJ3ledxD4e","execution":{"iopub.status.busy":"2024-10-31T22:36:30.611393Z","iopub.execute_input":"2024-10-31T22:36:30.611694Z","iopub.status.idle":"2024-10-31T22:36:30.620997Z","shell.execute_reply.started":"2024-10-31T22:36:30.611661Z","shell.execute_reply":"2024-10-31T22:36:30.620186Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"id":"P9Yi0Ymby533","outputId":"93a4fa52-868b-4fa8-c3e1-37d0fe760c32","execution":{"iopub.status.busy":"2024-10-31T22:36:32.611689Z","iopub.execute_input":"2024-10-31T22:36:32.612668Z","iopub.status.idle":"2024-10-31T22:36:32.634206Z","shell.execute_reply.started":"2024-10-31T22:36:32.612624Z","shell.execute_reply":"2024-10-31T22:36:32.633152Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   Country   Age   Salary Purchased\n0   France  44.0  72000.0        No\n1    Spain  27.0  48000.0       Yes\n2  Germany  30.0  54000.0        No\n3    Spain  38.0  61000.0        No\n4  Germany  40.0      NaN       Yes\n5   France  35.0  58000.0       Yes\n6    Spain   NaN  52000.0        No\n7   France  48.0  79000.0       Yes\n8  Germany  50.0  83000.0        No\n9   France  37.0  67000.0       Yes","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Age</th>\n      <th>Salary</th>\n      <th>Purchased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>France</td>\n      <td>44.0</td>\n      <td>72000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Spain</td>\n      <td>27.0</td>\n      <td>48000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Germany</td>\n      <td>30.0</td>\n      <td>54000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Spain</td>\n      <td>38.0</td>\n      <td>61000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Germany</td>\n      <td>40.0</td>\n      <td>NaN</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>France</td>\n      <td>35.0</td>\n      <td>58000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Spain</td>\n      <td>NaN</td>\n      <td>52000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>France</td>\n      <td>48.0</td>\n      <td>79000.0</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Germany</td>\n      <td>50.0</td>\n      <td>83000.0</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>France</td>\n      <td>37.0</td>\n      <td>67000.0</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#independent variables\nX =dataset.iloc[:,:-1].values\nX","metadata":{"id":"Wtgpleq5y72k","outputId":"5051ae14-ab05-4ba5-c50d-10eeafbebfa2","execution":{"iopub.status.busy":"2024-10-31T22:36:34.45787Z","iopub.execute_input":"2024-10-31T22:36:34.458283Z","iopub.status.idle":"2024-10-31T22:36:34.468971Z","shell.execute_reply.started":"2024-10-31T22:36:34.458247Z","shell.execute_reply":"2024-10-31T22:36:34.467928Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array([['France', 44.0, 72000.0],\n       ['Spain', 27.0, 48000.0],\n       ['Germany', 30.0, 54000.0],\n       ['Spain', 38.0, 61000.0],\n       ['Germany', 40.0, nan],\n       ['France', 35.0, 58000.0],\n       ['Spain', nan, 52000.0],\n       ['France', 48.0, 79000.0],\n       ['Germany', 50.0, 83000.0],\n       ['France', 37.0, 67000.0]], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"#dependent variable\nY = dataset.iloc[:,3].values\nY","metadata":{"id":"0Yxp7uZGzO-1","outputId":"532c6b3b-4ab4-4acf-b50d-3090eaf6f8f8","execution":{"iopub.status.busy":"2024-10-31T22:36:35.346802Z","iopub.execute_input":"2024-10-31T22:36:35.347226Z","iopub.status.idle":"2024-10-31T22:36:35.355216Z","shell.execute_reply.started":"2024-10-31T22:36:35.347187Z","shell.execute_reply":"2024-10-31T22:36:35.354063Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"#handle missing values\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\n\nimputer = SimpleImputer(missing_values = np.NaN, strategy = 'mean', )\nimputer = imputer.fit(X[:, 1:3])\nX[:,1:3]=imputer.transform(X[:,1:3])\n\nprint(X)","metadata":{"id":"1ryH9KAs1_gG","outputId":"ea3ec3a0-5a14-4f5a-bfe8-3f7e26a41b10","execution":{"iopub.status.busy":"2024-10-31T22:36:36.264533Z","iopub.execute_input":"2024-10-31T22:36:36.26518Z","iopub.status.idle":"2024-10-31T22:36:36.888813Z","shell.execute_reply.started":"2024-10-31T22:36:36.265125Z","shell.execute_reply":"2024-10-31T22:36:36.887726Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[['France' 44.0 72000.0]\n ['Spain' 27.0 48000.0]\n ['Germany' 30.0 54000.0]\n ['Spain' 38.0 61000.0]\n ['Germany' 40.0 63777.77777777778]\n ['France' 35.0 58000.0]\n ['Spain' 38.77777777777778 52000.0]\n ['France' 48.0 79000.0]\n ['Germany' 50.0 83000.0]\n ['France' 37.0 67000.0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"#handle categorical data\nfrom sklearn.preprocessing import OneHotEncoder , LabelEncoder\nencoder = LabelEncoder()\nY = encoder.fit_transform(Y)\n\nprint(Y)","metadata":{"id":"wxrPQ8zB2uTm","outputId":"3bf09d79-5709-443f-c6d6-0bb850556a01","execution":{"iopub.status.busy":"2024-10-31T22:38:32.59399Z","iopub.execute_input":"2024-10-31T22:38:32.594445Z","iopub.status.idle":"2024-10-31T22:38:32.601033Z","shell.execute_reply.started":"2024-10-31T22:38:32.594407Z","shell.execute_reply":"2024-10-31T22:38:32.599936Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[0 1 0 0 1 1 0 1 0 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"oneHotEncoder = OneHotEncoder()\nX_transformed = oneHotEncoder.fit_transform(X[:,[0]]).toarray()\n# Reshape the remaining columns to ensure they have two dimensions\nX_remaining = X[:, 1:].reshape(X.shape[0], -1)\nX_encoded = np.hstack((X_transformed , X_remaining))\n\nprint(X_encoded)","metadata":{"id":"MWHNkKUM39PF","outputId":"5c8785c4-051d-4a43-825e-42e2912dd8d1","execution":{"iopub.status.busy":"2024-10-31T22:38:38.660711Z","iopub.execute_input":"2024-10-31T22:38:38.661683Z","iopub.status.idle":"2024-10-31T22:38:38.669557Z","shell.execute_reply.started":"2024-10-31T22:38:38.661643Z","shell.execute_reply":"2024-10-31T22:38:38.66837Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[[1.0 0.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 1.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 1.0 0.0 40.0 63777.77777777778]\n [1.0 0.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [1.0 0.0 0.0 48.0 79000.0]\n [0.0 1.0 0.0 50.0 83000.0]\n [1.0 0.0 0.0 37.0 67000.0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_encoded, Y, test_size=0.2, random_state=42)\n","metadata":{"id":"CW7bK_vO4iy5","execution":{"iopub.status.busy":"2024-10-31T22:38:52.728024Z","iopub.execute_input":"2024-10-31T22:38:52.728737Z","iopub.status.idle":"2024-10-31T22:38:52.734877Z","shell.execute_reply.started":"2024-10-31T22:38:52.728695Z","shell.execute_reply":"2024-10-31T22:38:52.733738Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#feature scaler\nfrom sklearn.preprocessing import StandardScaler\n\nsts = StandardScaler()\nX_train[:,3:5] = sts.fit_transform(X_train[:,3:5])\nX_test[:,3:5] = sts.transform(X_test[:,3:5])\n\nprint(X_train)","metadata":{"id":"649l1c6Dpy8t","outputId":"ef692038-12de-4b27-b851-2b1112cc774c","execution":{"iopub.status.busy":"2024-10-31T22:39:03.797317Z","iopub.execute_input":"2024-10-31T22:39:03.797754Z","iopub.status.idle":"2024-10-31T22:39:03.806175Z","shell.execute_reply.started":"2024-10-31T22:39:03.797718Z","shell.execute_reply":"2024-10-31T22:39:03.805162Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[[1.0 0.0 0.0 -0.7529426005471072 -0.6260377781240918]\n [1.0 0.0 0.0 1.008453807952985 1.0130429500553495]\n [1.0 0.0 0.0 1.7912966561752484 1.8325833141450703]\n [0.0 1.0 0.0 -1.7314961608249362 -1.0943465576039322]\n [1.0 0.0 0.0 -0.3615211764359756 0.42765697570554906]\n [0.0 1.0 0.0 0.22561095973072184 0.05040823668012247]\n [0.0 0.0 1.0 -0.16581046438040975 -0.27480619351421154]\n [0.0 0.0 1.0 -0.013591021670525094 -1.3285009473438525]]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n\n\nmodels = [\n    ('Linear Regression', LinearRegression()),\n    ('Ridge Regression', Ridge()),\n    ('Lasso Regression', Lasso()),\n    ('Decision Tree', DecisionTreeRegressor()),\n    ('Random Forest', RandomForestRegressor()),\n    ('Support Vector Regression', SVR()),\n    ('XGBoost', XGBRegressor(objective='reg:squarederror', random_state=42))\n]\n\n# Dictionary to store the MSE for each model\nmse_scores = {}\n\n# Evaluate each model\nfor name, model in models:\n    # Fit the model to the training data\n    model.fit(X_train, y_train)\n\n    # Predict the target variable on the test data\n    y_pred = model.predict(X_test)\n\n    # Calculate the Mean Squared Error (MSE)\n    mse = mean_squared_error(y_test, y_pred)\n\n    # Store the MSE score in the dictionary\n    mse_scores[name] = mse\n    r2 = r2_score(y_test, y_pred)\n\n    print(f\"{name}: MSE = {mse:.3f} \\n R^2 Score = {r2:.4f}\")\n\n\n\n# Find the model with the lowest MSE\nbest_model_name = min(mse_scores, key=mse_scores.get)\nbest_mse = mse_scores[best_model_name]\n\nprint(f\"\\nBest Model: {best_model_name} with MSE = {best_mse:.3f}\")","metadata":{"id":"kBTEWBkI958m","outputId":"1bd16bb2-1e7a-48bc-f2d6-f7cbf9781752","execution":{"iopub.status.busy":"2024-10-31T22:39:08.500426Z","iopub.execute_input":"2024-10-31T22:39:08.500825Z","iopub.status.idle":"2024-10-31T22:39:12.804463Z","shell.execute_reply.started":"2024-10-31T22:39:08.50079Z","shell.execute_reply":"2024-10-31T22:39:12.803199Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Linear Regression: MSE = 0.910 \n R^2 Score = -2.6391\nRidge Regression: MSE = 0.746 \n R^2 Score = -1.9827\nLasso Regression: MSE = 0.250 \n R^2 Score = 0.0000\nDecision Tree: MSE = 1.000 \n R^2 Score = -3.0000\nRandom Forest: MSE = 0.675 \n R^2 Score = -1.7010\nSupport Vector Regression: MSE = 0.557 \n R^2 Score = -1.2266\nXGBoost: MSE = 1.005 \n R^2 Score = -3.0184\n\nBest Model: Lasso Regression with MSE = 0.250\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}