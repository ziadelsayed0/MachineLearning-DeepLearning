{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Text-to-Speech (TTS) Models\n\n## 1. English Text-to-Speech Model  \n- This model is based on **VITS (Variational Inference Text-to-Speech)** and is sourced from **kakao-enterprise/vits-ljs**.  \n- It uses `AutoTokenizer` and `AutoModelForTextToWaveform` from Hugging Face‚Äôs Transformers library.  \n- The model is pre-trained on **LJSpeech**, a widely used dataset for English speech synthesis.  \n- Capable of generating high-quality, natural-sounding **English** speech from text.  \n\n## 2. Arabic Text-to-Speech Model  \n- This model is from **Mohamed Bin Zayed University (MBZUAI)** and is based on **SpeechT5** with the `clartts_ar` configuration.  \n- It utilizes the `pipeline` function from Hugging Face to streamline Arabic TTS processing.  \n- The model is fine-tuned for **Arabic** speech synthesis.  \n- Generates clear and natural **Arabic** speech from text.  \n\nBoth models leverage advanced deep learning techniques to deliver **high-quality** speech synthesis in their respective languages. üöÄ\n","metadata":{}},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForTextToWaveform\n\ntokenizer = AutoTokenizer.from_pretrained(\"kakao-enterprise/vits-ljs\")\nmodel = AutoModelForTextToWaveform.from_pretrained(\"kakao-enterprise/vits-ljs\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:27:00.528435Z","iopub.execute_input":"2025-02-01T20:27:00.528759Z","iopub.status.idle":"2025-02-01T20:27:08.254551Z","shell.execute_reply.started":"2025-02-01T20:27:00.528727Z","shell.execute_reply":"2025-02-01T20:27:08.253589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install phonemizer ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!apt-get install espeak","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ntext = \"The error message cannot open backup device. Operating system error 3 The system cannot find the path specified means that SQL Server is unable to locate or access the specified directory. Here‚Äôs how to fix it\"\n\ninputs = tokenizer(text, return_tensors =\"pt\")\n\nwith torch.no_grad():\n    speech = model(**inputs).waveform","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:29:44.991286Z","iopub.execute_input":"2025-02-01T20:29:44.991588Z","iopub.status.idle":"2025-02-01T20:30:16.027353Z","shell.execute_reply.started":"2025-02-01T20:29:44.991566Z","shell.execute_reply":"2025-02-01T20:30:16.026524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install --upgrade --force-reinstall ipython -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:33:19.557157Z","iopub.execute_input":"2025-02-01T20:33:19.557484Z","iopub.status.idle":"2025-02-01T20:33:29.318565Z","shell.execute_reply.started":"2025-02-01T20:33:19.557456Z","shell.execute_reply":"2025-02-01T20:33:29.317504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Audio\nAudio(speech, rate=model.config.sampling_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:33:31.333550Z","iopub.execute_input":"2025-02-01T20:33:31.333911Z","iopub.status.idle":"2025-02-01T20:33:31.361330Z","shell.execute_reply.started":"2025-02-01T20:33:31.333875Z","shell.execute_reply":"2025-02-01T20:33:31.360291Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## This model form Mohammed Ben Salman Unvirsity\n### It's Microsoft model and the (Mohammed Ben Salman Unvirsity) finetuned it to on the arabic langauge","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nfrom datasets import load_dataset\nimport soundfile as sf\n\nsynthesiser = pipeline(\"text-to-speech\", \"MBZUAI/speecht5_tts_clartts_ar\")\n\nembeddings_dataset = load_dataset(\"herwoww/arabic_xvector_embeddings\", split=\"validation\")\nspeaker_embedding = torch.tensor(embeddings_dataset[105][\"speaker_embeddings\"]).unsqueeze(0)\n# You can replace this embedding with your own as well.\n\nspeech = synthesiser(\"ŸÑÿ£ŸÜŸá ŸÑÿß Ÿäÿ±Ÿâ ÿ£ŸÜŸá ÿπŸÑŸâ ÿßŸÑÿ≥ŸÅŸá ÿ´ŸÖ ŸÖŸÜ ÿ®ÿπÿØ ÿ∞ŸÑŸÉ ÿ≠ÿØŸäÿ´ ŸÖŸÜÿ™ÿ¥ÿ±\", forward_params={\"speaker_embeddings\": speaker_embedding})\n# ArTST is trained without diacritics.\n\nsf.write(\"speech.wav\", speech[\"audio\"], samplerate=speech[\"sampling_rate\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:33:35.742105Z","iopub.execute_input":"2025-02-01T20:33:35.742412Z","iopub.status.idle":"2025-02-01T20:34:03.590226Z","shell.execute_reply.started":"2025-02-01T20:33:35.742388Z","shell.execute_reply":"2025-02-01T20:34:03.589353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Audio('speech.wav')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T20:34:19.801894Z","iopub.execute_input":"2025-02-01T20:34:19.803167Z","iopub.status.idle":"2025-02-01T20:34:19.817843Z","shell.execute_reply.started":"2025-02-01T20:34:19.803129Z","shell.execute_reply":"2025-02-01T20:34:19.816929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}